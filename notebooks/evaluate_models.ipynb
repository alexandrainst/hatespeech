{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f3fe5-fd0a-4707-8325-1e581b3ef479",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ac237-99b7-4012-889d-50579a8e5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import nltk\n",
    "from src.hatespeech.attack import load_attack\n",
    "nltk.download('punkt')\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d1f34-4ae9-48f5-b870-1f34d30ec2a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0649b59a-c316-49f4-89b8-487a370c655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(text: str, tok, model) -> torch.Tensor:\n",
    "    if tok.model_max_length > 100_000:\n",
    "        tok.model_max_length = 512\n",
    "    toks = tok(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(\n",
    "            input_ids=toks[\"input_ids\"], \n",
    "            attention_mask=toks[\"attention_mask\"]\n",
    "        )[0]\n",
    "    if len(logits.shape) == 2:\n",
    "        logits = logits[0]\n",
    "    return logits[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a4f9f-ce7c-4674-ba41-c40a438979b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"data/final/train-off.parquet\")\n",
    "val_df = pd.read_parquet(\"data/final/val-off.parquet\")\n",
    "test_df = pd.read_parquet(\"data/final/test-off.parquet\")\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5eb235-4d70-4033-949f-8537ec599802",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate models on the agreed labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925e38b-391e-4ab6-9f94-0f2f7da84211",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = [1 if lbl == \"Offensive\" else 0 for lbl in val_df.label]\n",
    "test_labels = [1 if lbl == \"Offensive\" else 0 for lbl in test_df.label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c95cfc-e73d-4bb2-a53a-5d93a1cab129",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"our XLMR-base model from the first iteration\", 'models/xlmr-base1'),\n",
    "    (\"our XLMR-base model from the second iteration\", 'models/xlmr-base2'),\n",
    "    (\"our XLMR-base model from the third iteration\", 'models/xlmr-base3'),\n",
    "    (\"our XLMR-large model from the second iteration\", 'models/xlmr-large'),\n",
    "    (\"our ELECTRA model from the second iteration\", 'models/aelaectra'),\n",
    "    (\"our ELECTRA model from the third iteration\", 'models/aelaectra2'),\n",
    "    (\"our ELECTRA model from the third iteration w/o contains_offensive_word\", 'models/no_contains_offensive_word_aelaectra2'),\n",
    "    (\"our ELECTRA model from the third iteration w/o contains_positive_swear_word\", 'models/no_contains_positive_swear_word_aelaectra2'),\n",
    "    (\"our ELECTRA model from the third iteration w/o has_been_moderated\", 'models/no_has_been_moderated_aelaectra2'),\n",
    "    (\"our ELECTRA model from the third iteration w/o has_positive_sentiment\", 'models/no_has_positive_sentiment_aelaectra2'),\n",
    "    (\"our ELECTRA model from the third iteration w/o is_all_caps\", 'models/no_is_all_caps_aelaectra2'),\n",
    "    (\"our ELECTRA model from the third iteration w/o is_dr_answer\", 'models/no_is_dr_answer_aelaectra2'),\n",
    "    (\"our ELECTRA model from the third iteration w/o is_mention\", 'models/no_is_mention_aelaectra2'),\n",
    "    (\"Guscode\", 'Guscode/DKbert-hatespeech-detection'),\n",
    "    (\"DaNLP BERT\", 'DaNLP/da-bert-hatespeech-classification'),\n",
    "    (\"DaNLP ELECTRA\", 'DaNLP/da-electra-hatespeech-detection'),\n",
    "    (\"A-ttack\", 'attack'),\n",
    "]\n",
    "\n",
    "with tqdm(models) as pbar:\n",
    "    for name, model_id in pbar:\n",
    "        \n",
    "        # Update progress bar description\n",
    "        pbar.set_description(f\"Evaluating {name}\")\n",
    "\n",
    "        # Load tokenizer and model\n",
    "        if model_id != \"attack\":\n",
    "            tok = AutoTokenizer.from_pretrained(model_id)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "        else:\n",
    "            tok, model = load_attack()\n",
    "            \n",
    "        for split_name, df, labels in [(\"val\", val_df, val_labels), (\"test\", test_df, test_labels)]:\n",
    "        \n",
    "            # Get predictions\n",
    "            preds = torch.stack(\n",
    "                [get_logits(doc, tok, model) for doc in tqdm(df.text, leave=False)]\n",
    "            ) > 0\n",
    "\n",
    "            # Compute scores\n",
    "            recall = recall_score(labels, preds)\n",
    "            precision = precision_score(labels, preds)\n",
    "            f1 = f1_score(labels, preds)\n",
    "            macro_f1 = f1_score(labels, preds, average='macro')\n",
    "\n",
    "            # Print scores\n",
    "            print(f'Scores for {name} on the {split_name} split:')\n",
    "            print(f'\\tRecall: {100 * recall:.2f}%')\n",
    "            print(f'\\tPrecision: {100 * precision:.2f}%')\n",
    "            print(f'\\tF1-score: {100 * f1:.2f}%')\n",
    "        \n",
    "    pbar.set_description(\"Evaluating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a58c05-2323-4615-a2f2-7dedbc656b31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2bf0e-e7e9-4af4-8525-c301f5abdbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'models/xlmr-base3'\n",
    "\n",
    "# Load tokenizer and model\n",
    "if model_id == 'attack':\n",
    "    tok, model = load_attack()\n",
    "else:\n",
    "    tok = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "\n",
    "# Get logits\n",
    "logits = torch.stack(\n",
    "    [get_logits(doc, tok, model) for doc in tqdm(val_df.text, leave=False)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99d812-85dc-4608-befb-a66ebdad64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the logits and equivalent probabilities to the validation dataframe\n",
    "val_df[\"model_logits\"] = logits.tolist()\n",
    "val_df[\"model_probs\"] = torch.sigmoid(logits).tolist()\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df8d18-159b-41e9-963d-63bd645c6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sample indices on which the model was wrong\n",
    "wrong_idxs = (\n",
    "    torch.nonzero((logits > 0) != torch.tensor(val_labels)).squeeze(1).tolist()\n",
    ")\n",
    "\n",
    "# Get the samples on which the model was wrong\n",
    "wrong_df = val_df.loc[wrong_idxs]\n",
    "\n",
    "# Sort the dataframe by absolute value of logits\n",
    "wrong_df = wrong_df.sort_values(by='model_logits', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "wrong_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
